{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n!pip install Livelossplot\nfrom livelossplot import PlotLossesKeras\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport scipy\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.utils import *\n# import pydot\n\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom colorama import Fore\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nimport xgboost as xgb\n\nprint(\"All modules have been imported\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"info=pd.read_csv(\"../input/mias-mammography/Info.txt\",sep=\" \")\ninfo=info.drop('Unnamed: 7',axis=1)\ninfo.SEVERITY.fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('darkgrid')\nfig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,5))\nsns.barplot(x=info.BG.unique(),y=info.BG.value_counts(),palette='Blues_r',ax=ax1)\nsns.barplot(x=info.CLASS.unique(),y=info.CLASS.value_counts(),palette='Blues_r',ax=ax2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport glob\nx= []\nfor filename in sorted(glob.glob(\"../input/mias-mammography/all-mias/*.pgm\")): \n    img=cv2.imread(filename)\n    img =cv2.resize(img,(224, 224))\n    x.append(img)\nfig=plt.figure(figsize=(15,15))\ncolumns = 3\nrows = 3\nfor i in range(1, columns*rows +1):\n    img = np.random.randint(10)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(x[i])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Augmentation\nno_angles = 360\nurl = '/kaggle/input/mias-mammography/all-mias/'\n\ndef save_dictionary(path,data):\n        print('saving catalog...')\n        #open('u.item', encoding=\"utf-8\")\n        import json\n        with open(path,'w') as outfile:\n            json.dump(str(data), fp=outfile)\n        # save to file:\n        print(' catalog saved')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_test_split_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\n# val_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\n# test_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\ndef read_image():\n        print(\"Reading images\")\n        import cv2\n        info = {}\n        for i in range(322):\n            if i<9:\n                image_name='mdb00'+str(i+1)\n            elif i<99:\n                image_name='mdb0'+str(i+1)\n            else:\n                image_name = 'mdb' + str(i+1)\n            image_address= url+image_name+'.pgm'\n            img = cv2.imread(image_address,1)\n            img = cv2.resize(img, (224,224))\n            rows, cols,channel = img.shape\n            info[image_name]={}\n            for angle in range(0,no_angles,8):\n                M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1) \n                img_rotated = cv2.warpAffine(img, M, (cols, rows))\n                info[image_name][angle]=img_rotated\n        return (info)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os #Operating System\nimport sys #System\n# train_generator = train_datagen.flow(x_train, y_train, batch_size =)\n# val_generator = val_datagen.flow(x_val, y_val, batch_size = 64)\n# test_generator=test_datagen.flow(x_test,y_test,batch_size = 64)\n\ndef get_script_path():\n    return os.path.dirname(os.path.realpath(sys.argv[0]))    \n\ndef read_lable():\n    filename = url+'Info.txt'\n    text_all = open(filename).read()\n    #print(text_all)\n    lines=text_all.split('\\n')\n    info={}\n    for line in lines:\n        words=line.split(' ')\n        if len(words)>1:\n            if (words[1] == 'G'):\n                info[words[0]] = {}\n                for angle in range(no_angles):\n                    info[words[0]][angle] = 2\n            if (words[1] == 'D'):\n                info[words[0]] = {}\n                for  angle in range(no_angles):\n                    info[words[0]][angle] = 1\n            if (words[1] == 'F'):\n                info[words[0]] = {}\n                for  angle in range(no_angles):\n                    info[words[0]][angle] = 0\n            \n    return (info)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nlable_info=read_lable()\nimage_info=read_image()\nids=lable_info.keys() \n#del lable_info['Truth-Data:']\nX=[]\nY=[]\nfor id in ids:\n    for angle in range(0,no_angles,8):\n        X.append(image_info[id][angle])\n        Y.append(lable_info[id][angle])\nX=np.array(X)\nY=np.array(Y)\nY=to_categorical(Y,3)\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n#x_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.3, random_state=42)\n#x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.3, random_state=42)\n#print(len(x_train),len(x_val),len(x_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Callbacks\n\n#c2=tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True, verbose=1)\nc2=tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=6,\n    mode=\"min\",\n    baseline=None,\n    restore_best_weights=True,)\n\nc3=tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=6,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=0,\n    min_lr=0.001)\nnClasses=3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Y_train=to_categorical(y_train,3)\n#Y_test=to_categorical(y_test,3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_Neural_Net= VGG16(input_shape=(224,224,3), weights='imagenet', include_top=False)\nmodel=Sequential()\nmodel.add(base_Neural_Net)\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3,activation='softmax'))\n\nfor layer in base_Neural_Net.layers:\n    layer.trainable = False\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#c1=PlotLossesKeras()\nmodel.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy', 'AUC'])\nhistory=model.fit(x_train,y_train,epochs=10,callbacks=[c2,c3],batch_size=16)\n\n#loss_value , accuracy = model.evaluate(x_test, y_test)\n\n#print('Test_loss_value = ' +str(loss_value))\n#print('test_accuracy = ' + str(accuracy))\n\n#print(model.predict(x_test))\n#model.save('breast_cance_model.h5')\n\nsave_dictionary('history1.dat', history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.evaluate(x_val,y_val,callbacks=[c2,c3],batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"['accu#%% PLOTTING RESULTS \nimport matplotlib.pyplot as plt\ndef Train_Val_Plot(acc,loss):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    #ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    #ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],\n               history.history['loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.evaluate(x_val,y_val,callbacks=[c2,c3],batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Performance Report:\")\n#y_pred=np.argmax(model.predict(x_test),axis=-1)\n#y_pred_prb=model.predict_proba(x_test)\ny_pred8=model.predict_classes(x_test)\ny_test8=[np.argmax(x) for x in y_test]\ny_pred_prb8=model.predict_proba(x_test)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test8, y_pred8),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test8, y_pred8, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test8,y_pred8, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test8, y_pred8, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test8, y_pred_prb8,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test8, y_pred8),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test8, y_pred8,target_names=target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',cmap=plt.cm.Blues):\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    plt.grid(False)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j,i,cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \ncm=confusion_matrix(y_test8,y_pred8)\ncm_plot=plot_confusion_matrix(cm,classes=['G','F','D'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}