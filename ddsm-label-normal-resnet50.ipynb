{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from collections import Counter\nfrom tensorflow.python.client import device_lib #GPU Check\nimport tensorflow.keras #keras\nimport cv2, gc\nimport os\nimport glob\nimport skimage\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport preprocessing\nfrom tqdm import tqdm\nfrom io import BytesIO\nfrom PIL import Image\nfrom os import listdir\nimport matplotlib.pyplot as plt\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom collections import Counter\nimport IPython.display as display\n\nsn.set()\n\nfrom sklearn.svm import SVC # SVC\nfrom sklearn import metrics\nfrom sklearn.utils import shuffle\nfrom xgboost import XGBClassifier # XGBClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.utils import compute_class_weight\nfrom sklearn.preprocessing import MinMaxScaler,LabelBinarizer\nfrom sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.initializers import glorot_uniform, he_uniform\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16 # VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19 # VGG19\nfrom tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\nfrom tensorflow.keras.applications.xception import Xception # Xception\nfrom tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\nfrom tensorflow.keras.applications.nasnet import NASNetMobile # NASNetMobile\nfrom tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\nfrom tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mirrored_strategy = tf.distribute.MirroredStrategy()\n#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \":/gpu:2\", \":gpu:3\"])\ndef reset_keras():\n    tensorflow.keras.backend.clear_session\nreset_keras()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# full_dataset = tf.data.TFRecordDataset(\"../input/ddsm-mammography/training10_0/training10_0.tfrecords\",num_parallel_reads=tf.data.experimental.AUTOTUNE)\n\n# full_dataset = full_dataset.shuffle(buffer_size=31000)\n\n# # train_dataset = full_dataset.take(100)\n# # val_dataset = full_dataset.skip(100).take(20)\n\n# full_dataset = full_dataset.cache()\n# # val_dataset = val_dataset.cache()\n\n# print(\"Size of Training Dataset: \", len(list(full_dataset)))\n# # print(\"Size of Validation Dataset: \", len(list(val_dataset)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for raw_record in full_dataset.take(1):\n#     example = tf.train.Example()\n#     example.ParseFromString(raw_record.numpy())\n#     if True:  # Change this to True if you want to see the data.  I turned it off because it's long and it make this notebook hard to read.\n#         print(example)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature_dictionary = {\n#     'label': tf.io.FixedLenFeature([], tf.int64),\n#     'label_normal': tf.io.FixedLenFeature([], tf.int64),\n#     'image': tf.io.FixedLenFeature([], tf.string)\n# }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def _parse_function(example, feature_dictionary=feature_dictionary):\n#     parsed_example = tf.io.parse_example(example, feature_dictionary)\n#     return parsed_example\n\n# full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n# # val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n# print(full_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images=[]\n# labels=[]\n# for image_features in full_dataset:\n#     image = image_features['image'].numpy()\n#     image = tf.io.decode_raw(image_features['image'], tf.uint8)\n#     image = tf.reshape(image, [299, 299])\n#     image=image.numpy()\n#     #plt.imshow(image)\n#     images.append(image)\n#     labels.append(image_features['label_normal'].numpy())\n#     print(\"Label is \" + str(image_features['label_normal'].numpy()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=[]\nlabels=[]\nfeature_dictionary = {\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n    'image': tf.io.FixedLenFeature([], tf.string)\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _parse_function(example, feature_dictionary=feature_dictionary):\n    parsed_example = tf.io.parse_example(example, feature_dictionary)\n    return parsed_example\n\ndef read_data(filename):\n    full_dataset = tf.data.TFRecordDataset(filename,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n    full_dataset = full_dataset.shuffle(buffer_size=31000)\n    full_dataset = full_dataset.cache()\n    print(\"Size of Training Dataset: \", len(list(full_dataset)))\n    \n    feature_dictionary = {\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n    'image': tf.io.FixedLenFeature([], tf.string)\n    }   \n\n    full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    print(full_dataset)\n    for image_features in full_dataset:\n        image = image_features['image'].numpy()\n        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n        image = tf.reshape(image, [299, 299])        \n        image=image.numpy()\n        image=cv2.resize(image,(100,100))\n        image=cv2.merge([image,image,image])        \n        #plt.imshow(image)\n        images.append(image)\n        labels.append(image_features['label_normal'].numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reset_keras()\nfilenames=['../input/ddsm-mammography/training10_0/training10_0.tfrecords',\n          '../input/ddsm-mammography/training10_1/training10_1.tfrecords',\n          '../input/ddsm-mammography/training10_2/training10_2.tfrecords',\n          '../input/ddsm-mammography/training10_3/training10_3.tfrecords',\n          '../input/ddsm-mammography/training10_4/training10_4.tfrecords']\n\nfor file in filenames:\n    read_data(file)\n    \nprint(len(images))\nprint(len(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(images)\ny=np.array(labels)\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2021,shuffle=True,stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x_train[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten\nfrom keras import optimizers\nfrom keras import losses\nfrom sklearn import metrics\n\nprint(x_train[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = ResNet50(input_shape=(100,100,3), weights='imagenet', include_top=False)\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nes = EarlyStopping(monitor='val_loss', mode='min', patience=6,restore_best_weights=True, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x_train, y_train,validation_split=0.2,shuffle=True, epochs=40, batch_size=128,callbacks=[es])\nloss_value , accuracy = model.evaluate(x_test, y_test)\n\nprint('Test_loss_value = ' +str(loss_value))\nprint('test_accuracy = ' + str(accuracy))\n\n#print(model.predict(x_test))\n#model.save('breast_cance_model.h5')\n\n#save_dictionary('history1.dat', history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef Train_Val_Plot(acc,val_acc,loss,val_loss):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict_classes(x_test)\ny_pred_prb=model.predict_proba(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target=[\"0\",\"1\"]\nfrom sklearn import metrics\nprint('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred),4))\nprint('Precision:', np.round(metrics.precision_score(y_test, y_pred, average='weighted'),4))\nprint('Recall:', np.round(metrics.recall_score(y_test,y_pred, average='weighted'),4))\nprint('F1 Score:', np.round(metrics.f1_score(y_test, y_pred, average='weighted'),4))\nprint('ROC AUC Score:', np.round(metrics.roc_auc_score(y_test, y_pred_prb,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, y_pred),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred,target_names=target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',cmap=plt.cm.Blues):\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    plt.grid(False)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j,i,cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \ncm=confusion_matrix(y_test,y_pred)\ncm_plot=plot_confusion_matrix(cm,classes=['0','1'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}