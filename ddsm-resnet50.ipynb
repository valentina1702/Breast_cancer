{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.client import device_lib #GPU Check\nimport tensorflow.keras #keras\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.utils import *\nfrom sklearn.metrics import *\nfrom collections import Counter\nimport cv2, gc\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport preprocessing\nfrom tqdm import tqdm\nfrom io import BytesIO\nfrom PIL import Image\nfrom os import listdir\nimport matplotlib.pyplot as plt\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom sklearn.utils import compute_class_weight\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.initializers import glorot_uniform, he_uniform\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"All modules have been imported\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mirrored_strategy = tf.distribute.MirroredStrategy()\n#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \":/gpu:2\", \":gpu:3\"])\ndef reset_keras():\n    tensorflow.keras.backend.clear_session\nreset_keras()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=[]\nlabels=[]\nfeature_dictionary = {\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n    'image': tf.io.FixedLenFeature([], tf.string)\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _parse_function(example, feature_dictionary=feature_dictionary):\n    parsed_example = tf.io.parse_example(example, feature_dictionary)\n    return parsed_example\n\ndef read_data(filename):\n    full_dataset = tf.data.TFRecordDataset(filename,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n    full_dataset = full_dataset.cache()\n    print(\"Size of Training Dataset: \", len(list(full_dataset)))\n    \n    feature_dictionary = {\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n    'image': tf.io.FixedLenFeature([], tf.string)\n    }   \n\n    full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    print(full_dataset)\n    for image_features in full_dataset:\n        image = image_features['image'].numpy()\n        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n        image = tf.reshape(image, [299, 299])        \n        image=image.numpy()\n        image=cv2.resize(image,(112,112))\n        image=cv2.merge([image,image,image])\n        image\n        images.append(image)\n        labels.append(image_features['label'].numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reset_keras()\nfilenames=['../input/ddsm-mammography/training10_0/training10_0.tfrecords',\n          '../input/ddsm-mammography/training10_1/training10_1.tfrecords',\n          '../input/ddsm-mammography/training10_2/training10_2.tfrecords',\n          '../input/ddsm-mammography/training10_3/training10_3.tfrecords',\n          '../input/ddsm-mammography/training10_4/training10_4.tfrecords'\n          ]\n\nfor file in filenames:\n    read_data(file)\n    \nprint(len(images))\nprint(len(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(images)\ny=np.array(labels)\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=True,stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fig=plt.figure(figsize=(15,15))\n#columns = 4\n#rows = 3\n#for i in range(1, columns*rows +1):\n    #img = np.random.randint(10)\n    #fig.add_subplot(rows, columns, i)\n    #plt.imshow(x_train[i])\n#plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten\nfrom keras import optimizers\nfrom keras import losses\nfrom sklearn import metrics\n\nprint(x_train[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_count=pd.DataFrame(y_train)\ny_count.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights={0:0.869,1:0.037,2:0.034,3:0.026,4:0.032}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = ResNet50(input_shape=(112,112,3), weights='imagenet', include_top=False)\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation='softmax'))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c1= tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\nc2=tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=2,\n    mode=\"auto\",\n    min_delta=0.0001,\n    cooldown=0,\n    min_lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train=to_categorical(y_train,5)\nY_test=to_categorical(y_test,5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])\nhistory = model.fit(x_train, Y_train,validation_split=0.2,shuffle=True, epochs=50, batch_size=128,callbacks=[c1,c2],\n                   class_weight=weights)\n#loss_value , accuracy = model.evaluate(x_test, Y_test)\n\n#print('Test_loss_value = ' +str(loss_value))\n#print('test_accuracy = ' + str(accuracy))\n\n#save_dictionary('history1.dat', history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% PLOTTING RESULTS \nimport matplotlib.pyplot as plt\ndef Train_Val_Plot(acc,val_acc,loss,val_loss):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=np.argmax(model.predict(x_test),axis=-1)\ny_pred_prb=model.predict_proba(x_test)\ntarget=[\"0\",\"1\",\"2\",\"3\",\"4\"]\nfrom sklearn import metrics\nprint('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred),5))\nprint('Precision:', np.round(metrics.precision_score(y_test, y_pred, average='weighted'),5))\nprint('Recall:', np.round(metrics.recall_score(y_test,y_pred, average='weighted'),5))\nprint('F1 Score:', np.round(metrics.f1_score(y_test, y_pred, average='weighted'),5))\nprint('ROC AUC Score:', np.round(metrics.roc_auc_score(y_test, y_pred_prb,multi_class='ovo', average='weighted'),5))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, y_pred),5))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred,target_names=target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=np.argmax(model.predict(x_test),axis=-1)\ncm=confusion_matrix(y_test,pred)\ncm_plot=plot_confusion_matrix(cm,classes=['0','1','2','3','4'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}